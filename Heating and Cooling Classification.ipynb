{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heating and Cooling load of the builing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables explanation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X1\t: Relative Compactness\n",
    "X2\t: Surface Area \n",
    "X3\t: Wall Area \n",
    "X4\t: Roof Area \n",
    "X5\t: Overall Height \n",
    "X6\t: Orientation \n",
    "X7\t: Glazing Area \n",
    "X8\t: Glazing Area Distribution \n",
    "y1\t: Heating Load \n",
    "y2\t: Cooling Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ENB2012_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.84</td>\n",
       "      <td>28.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X1     X2     X3      X4   X5  X6   X7  X8     Y1     Y2\n",
       "0  0.98  514.5  294.0  110.25  7.0   2  0.0   0  15.55  21.33\n",
       "1  0.98  514.5  294.0  110.25  7.0   3  0.0   0  15.55  21.33\n",
       "2  0.98  514.5  294.0  110.25  7.0   4  0.0   0  15.55  21.33\n",
       "3  0.98  514.5  294.0  110.25  7.0   5  0.0   0  15.55  21.33\n",
       "4  0.90  563.5  318.5  122.50  7.0   2  0.0   0  20.84  28.28"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine cooling data and heating data to find the overall load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Y\"] = data[\"Y1\"].add(data[\"Y2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "      <td>36.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "      <td>36.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "      <td>36.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "      <td>36.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.84</td>\n",
       "      <td>28.28</td>\n",
       "      <td>49.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X1     X2     X3      X4   X5  X6   X7  X8     Y1     Y2      Y\n",
       "0  0.98  514.5  294.0  110.25  7.0   2  0.0   0  15.55  21.33  36.88\n",
       "1  0.98  514.5  294.0  110.25  7.0   3  0.0   0  15.55  21.33  36.88\n",
       "2  0.98  514.5  294.0  110.25  7.0   4  0.0   0  15.55  21.33  36.88\n",
       "3  0.98  514.5  294.0  110.25  7.0   5  0.0   0  15.55  21.33  36.88\n",
       "4  0.90  563.5  318.5  122.50  7.0   2  0.0   0  20.84  28.28  49.12"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide Y into three classes\n",
    "1 = high efficiency\n",
    "2 = average efficiency\n",
    "3 = low efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Y'] = pd.cut(data['Y'], 3, labels=[1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.84</td>\n",
       "      <td>28.28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.46</td>\n",
       "      <td>25.38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.71</td>\n",
       "      <td>25.16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.68</td>\n",
       "      <td>29.60</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.86</td>\n",
       "      <td>588.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.50</td>\n",
       "      <td>27.30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.86</td>\n",
       "      <td>588.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.95</td>\n",
       "      <td>21.97</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.86</td>\n",
       "      <td>588.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.34</td>\n",
       "      <td>23.49</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.86</td>\n",
       "      <td>588.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.31</td>\n",
       "      <td>27.87</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.82</td>\n",
       "      <td>612.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.05</td>\n",
       "      <td>23.77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.82</td>\n",
       "      <td>612.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.41</td>\n",
       "      <td>21.46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.82</td>\n",
       "      <td>612.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.95</td>\n",
       "      <td>21.16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.82</td>\n",
       "      <td>612.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.98</td>\n",
       "      <td>24.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.79</td>\n",
       "      <td>637.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.52</td>\n",
       "      <td>37.73</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.79</td>\n",
       "      <td>637.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.90</td>\n",
       "      <td>31.27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.79</td>\n",
       "      <td>637.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.63</td>\n",
       "      <td>30.93</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.79</td>\n",
       "      <td>637.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.75</td>\n",
       "      <td>39.44</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.76</td>\n",
       "      <td>661.5</td>\n",
       "      <td>416.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.77</td>\n",
       "      <td>29.79</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.76</td>\n",
       "      <td>661.5</td>\n",
       "      <td>416.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.93</td>\n",
       "      <td>29.68</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.76</td>\n",
       "      <td>661.5</td>\n",
       "      <td>416.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.77</td>\n",
       "      <td>29.79</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.76</td>\n",
       "      <td>661.5</td>\n",
       "      <td>416.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.93</td>\n",
       "      <td>29.40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.74</td>\n",
       "      <td>686.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.07</td>\n",
       "      <td>10.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.74</td>\n",
       "      <td>686.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.05</td>\n",
       "      <td>11.19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.74</td>\n",
       "      <td>686.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.01</td>\n",
       "      <td>10.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.74</td>\n",
       "      <td>686.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.04</td>\n",
       "      <td>11.17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.71</td>\n",
       "      <td>710.5</td>\n",
       "      <td>269.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.37</td>\n",
       "      <td>11.27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.71</td>\n",
       "      <td>710.5</td>\n",
       "      <td>269.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.40</td>\n",
       "      <td>11.72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>0.79</td>\n",
       "      <td>637.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>41.09</td>\n",
       "      <td>47.01</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>0.79</td>\n",
       "      <td>637.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>40.79</td>\n",
       "      <td>44.87</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>0.76</td>\n",
       "      <td>661.5</td>\n",
       "      <td>416.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>38.82</td>\n",
       "      <td>39.37</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>0.76</td>\n",
       "      <td>661.5</td>\n",
       "      <td>416.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>39.72</td>\n",
       "      <td>39.80</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>0.76</td>\n",
       "      <td>661.5</td>\n",
       "      <td>416.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>39.31</td>\n",
       "      <td>37.79</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>0.76</td>\n",
       "      <td>661.5</td>\n",
       "      <td>416.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>39.86</td>\n",
       "      <td>38.18</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>0.74</td>\n",
       "      <td>686.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>14.41</td>\n",
       "      <td>16.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>0.74</td>\n",
       "      <td>686.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>14.19</td>\n",
       "      <td>16.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>0.74</td>\n",
       "      <td>686.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>14.17</td>\n",
       "      <td>16.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>0.74</td>\n",
       "      <td>686.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>14.39</td>\n",
       "      <td>16.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>0.71</td>\n",
       "      <td>710.5</td>\n",
       "      <td>269.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>12.43</td>\n",
       "      <td>15.59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>0.71</td>\n",
       "      <td>710.5</td>\n",
       "      <td>269.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>12.63</td>\n",
       "      <td>14.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>0.71</td>\n",
       "      <td>710.5</td>\n",
       "      <td>269.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>12.76</td>\n",
       "      <td>15.33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>0.71</td>\n",
       "      <td>710.5</td>\n",
       "      <td>269.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>12.42</td>\n",
       "      <td>15.31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>0.69</td>\n",
       "      <td>735.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>14.12</td>\n",
       "      <td>16.63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>0.69</td>\n",
       "      <td>735.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>14.28</td>\n",
       "      <td>15.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>0.69</td>\n",
       "      <td>735.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>14.37</td>\n",
       "      <td>16.54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>0.69</td>\n",
       "      <td>735.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>14.21</td>\n",
       "      <td>16.74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>0.66</td>\n",
       "      <td>759.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>14.96</td>\n",
       "      <td>17.64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>0.66</td>\n",
       "      <td>759.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>14.92</td>\n",
       "      <td>17.79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>0.66</td>\n",
       "      <td>759.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>14.92</td>\n",
       "      <td>17.55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>0.66</td>\n",
       "      <td>759.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>15.16</td>\n",
       "      <td>18.06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>0.64</td>\n",
       "      <td>784.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>17.69</td>\n",
       "      <td>20.82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>0.64</td>\n",
       "      <td>784.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>18.19</td>\n",
       "      <td>20.21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>0.64</td>\n",
       "      <td>784.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>18.16</td>\n",
       "      <td>20.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0.64</td>\n",
       "      <td>784.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>17.88</td>\n",
       "      <td>21.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>16.54</td>\n",
       "      <td>16.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>16.44</td>\n",
       "      <td>17.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>16.48</td>\n",
       "      <td>16.61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>16.64</td>\n",
       "      <td>16.03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       X1     X2     X3      X4   X5  X6   X7  X8     Y1     Y2  Y\n",
       "0    0.98  514.5  294.0  110.25  7.0   2  0.0   0  15.55  21.33  1\n",
       "1    0.98  514.5  294.0  110.25  7.0   3  0.0   0  15.55  21.33  1\n",
       "2    0.98  514.5  294.0  110.25  7.0   4  0.0   0  15.55  21.33  1\n",
       "3    0.98  514.5  294.0  110.25  7.0   5  0.0   0  15.55  21.33  1\n",
       "4    0.90  563.5  318.5  122.50  7.0   2  0.0   0  20.84  28.28  2\n",
       "5    0.90  563.5  318.5  122.50  7.0   3  0.0   0  21.46  25.38  2\n",
       "6    0.90  563.5  318.5  122.50  7.0   4  0.0   0  20.71  25.16  2\n",
       "7    0.90  563.5  318.5  122.50  7.0   5  0.0   0  19.68  29.60  2\n",
       "8    0.86  588.0  294.0  147.00  7.0   2  0.0   0  19.50  27.30  2\n",
       "9    0.86  588.0  294.0  147.00  7.0   3  0.0   0  19.95  21.97  2\n",
       "10   0.86  588.0  294.0  147.00  7.0   4  0.0   0  19.34  23.49  2\n",
       "11   0.86  588.0  294.0  147.00  7.0   5  0.0   0  18.31  27.87  2\n",
       "12   0.82  612.5  318.5  147.00  7.0   2  0.0   0  17.05  23.77  1\n",
       "13   0.82  612.5  318.5  147.00  7.0   3  0.0   0  17.41  21.46  1\n",
       "14   0.82  612.5  318.5  147.00  7.0   4  0.0   0  16.95  21.16  1\n",
       "15   0.82  612.5  318.5  147.00  7.0   5  0.0   0  15.98  24.93  1\n",
       "16   0.79  637.0  343.0  147.00  7.0   2  0.0   0  28.52  37.73  3\n",
       "17   0.79  637.0  343.0  147.00  7.0   3  0.0   0  29.90  31.27  2\n",
       "18   0.79  637.0  343.0  147.00  7.0   4  0.0   0  29.63  30.93  2\n",
       "19   0.79  637.0  343.0  147.00  7.0   5  0.0   0  28.75  39.44  3\n",
       "20   0.76  661.5  416.5  122.50  7.0   2  0.0   0  24.77  29.79  2\n",
       "21   0.76  661.5  416.5  122.50  7.0   3  0.0   0  23.93  29.68  2\n",
       "22   0.76  661.5  416.5  122.50  7.0   4  0.0   0  24.77  29.79  2\n",
       "23   0.76  661.5  416.5  122.50  7.0   5  0.0   0  23.93  29.40  2\n",
       "24   0.74  686.0  245.0  220.50  3.5   2  0.0   0   6.07  10.90  1\n",
       "25   0.74  686.0  245.0  220.50  3.5   3  0.0   0   6.05  11.19  1\n",
       "26   0.74  686.0  245.0  220.50  3.5   4  0.0   0   6.01  10.94  1\n",
       "27   0.74  686.0  245.0  220.50  3.5   5  0.0   0   6.04  11.17  1\n",
       "28   0.71  710.5  269.5  220.50  3.5   2  0.0   0   6.37  11.27  1\n",
       "29   0.71  710.5  269.5  220.50  3.5   3  0.0   0   6.40  11.72  1\n",
       "..    ...    ...    ...     ...  ...  ..  ...  ..    ...    ... ..\n",
       "738  0.79  637.0  343.0  147.00  7.0   4  0.4   5  41.09  47.01  3\n",
       "739  0.79  637.0  343.0  147.00  7.0   5  0.4   5  40.79  44.87  3\n",
       "740  0.76  661.5  416.5  122.50  7.0   2  0.4   5  38.82  39.37  3\n",
       "741  0.76  661.5  416.5  122.50  7.0   3  0.4   5  39.72  39.80  3\n",
       "742  0.76  661.5  416.5  122.50  7.0   4  0.4   5  39.31  37.79  3\n",
       "743  0.76  661.5  416.5  122.50  7.0   5  0.4   5  39.86  38.18  3\n",
       "744  0.74  686.0  245.0  220.50  3.5   2  0.4   5  14.41  16.69  1\n",
       "745  0.74  686.0  245.0  220.50  3.5   3  0.4   5  14.19  16.62  1\n",
       "746  0.74  686.0  245.0  220.50  3.5   4  0.4   5  14.17  16.94  1\n",
       "747  0.74  686.0  245.0  220.50  3.5   5  0.4   5  14.39  16.70  1\n",
       "748  0.71  710.5  269.5  220.50  3.5   2  0.4   5  12.43  15.59  1\n",
       "749  0.71  710.5  269.5  220.50  3.5   3  0.4   5  12.63  14.58  1\n",
       "750  0.71  710.5  269.5  220.50  3.5   4  0.4   5  12.76  15.33  1\n",
       "751  0.71  710.5  269.5  220.50  3.5   5  0.4   5  12.42  15.31  1\n",
       "752  0.69  735.0  294.0  220.50  3.5   2  0.4   5  14.12  16.63  1\n",
       "753  0.69  735.0  294.0  220.50  3.5   3  0.4   5  14.28  15.87  1\n",
       "754  0.69  735.0  294.0  220.50  3.5   4  0.4   5  14.37  16.54  1\n",
       "755  0.69  735.0  294.0  220.50  3.5   5  0.4   5  14.21  16.74  1\n",
       "756  0.66  759.5  318.5  220.50  3.5   2  0.4   5  14.96  17.64  1\n",
       "757  0.66  759.5  318.5  220.50  3.5   3  0.4   5  14.92  17.79  1\n",
       "758  0.66  759.5  318.5  220.50  3.5   4  0.4   5  14.92  17.55  1\n",
       "759  0.66  759.5  318.5  220.50  3.5   5  0.4   5  15.16  18.06  1\n",
       "760  0.64  784.0  343.0  220.50  3.5   2  0.4   5  17.69  20.82  1\n",
       "761  0.64  784.0  343.0  220.50  3.5   3  0.4   5  18.19  20.21  1\n",
       "762  0.64  784.0  343.0  220.50  3.5   4  0.4   5  18.16  20.71  1\n",
       "763  0.64  784.0  343.0  220.50  3.5   5  0.4   5  17.88  21.40  1\n",
       "764  0.62  808.5  367.5  220.50  3.5   2  0.4   5  16.54  16.88  1\n",
       "765  0.62  808.5  367.5  220.50  3.5   3  0.4   5  16.44  17.11  1\n",
       "766  0.62  808.5  367.5  220.50  3.5   4  0.4   5  16.48  16.61  1\n",
       "767  0.62  808.5  367.5  220.50  3.5   5  0.4   5  16.64  16.03  1\n",
       "\n",
       "[768 rows x 11 columns]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['Y1','Y2','Y'], axis = 1)\n",
    "y = data['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X1     X2     X3      X4   X5  X6   X7  X8\n",
       "0  0.98  514.5  294.0  110.25  7.0   2  0.0   0\n",
       "1  0.98  514.5  294.0  110.25  7.0   3  0.0   0\n",
       "2  0.98  514.5  294.0  110.25  7.0   4  0.0   0\n",
       "3  0.98  514.5  294.0  110.25  7.0   5  0.0   0\n",
       "4  0.90  563.5  318.5  122.50  7.0   2  0.0   0"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    2\n",
       "Name: Y, dtype: category\n",
       "Categories (3, int64): [1 < 2 < 3]"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split and scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_a = scaler.fit_transform(X_train)\n",
    "X_test_a = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run different models to find the best one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN classification\n",
    "Picked 5 as the neighbor from the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 3, 4, 5, 10, 20, 50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "\n",
    "param_grid = {'n_neighbors':[1,3,4,5, 10, 20, 50]}\n",
    "\n",
    "grid_search = GridSearchCV(knn_clf , param_grid, cv = 10 , return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 5}"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 5).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r2: 0.94017\n",
      "Test r2: 0.89055\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_train_predict = knn.predict(X_train)\n",
    "y_test_predict = knn.predict(X_test)\n",
    "\n",
    "print('Train r2: {:.5f}'.format(r2_score(y_train, y_train_predict)))\n",
    "print('Test r2: {:.5f}'.format(r2_score(y_test, y_test_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 3, 2, 2, 2, 2, 2, 2, 2, 1, 3, 1, 3, 3, 2, 1, 3, 1, 1, 1, 2, 1,\n",
       "       3, 1, 1, 1, 1, 1, 3, 1, 1, 3, 1, 2, 3, 1, 3, 1, 1, 1, 3, 1, 2, 2, 2,\n",
       "       1, 1, 2, 2, 2, 1, 3, 1, 3, 1, 2, 2, 3, 1, 1, 1, 3, 1, 1, 1, 3, 1, 2,\n",
       "       3, 2, 1, 2, 1, 1, 2, 2, 3, 2, 1, 3, 2, 1, 1, 2, 2, 2, 3, 1, 1, 1, 2,\n",
       "       1, 2, 3, 1, 2, 1, 1, 3, 3, 2, 2, 3, 1, 2, 3, 1, 1, 2, 1, 3, 2, 1, 1,\n",
       "       1, 1, 3, 2, 3, 3, 1, 1, 3, 1, 3, 1, 2, 1, 2, 3, 2, 3, 1, 3, 1, 2, 2,\n",
       "       3, 1, 1, 1, 2, 1, 3, 1, 2, 3, 1, 1, 2, 1, 1, 1, 1, 3, 3, 2, 1, 2, 3,\n",
       "       1, 2, 2, 1, 1, 1, 2, 1, 2, 3, 1, 3, 3, 3, 2, 2, 2, 1, 2, 1, 3, 2, 1,\n",
       "       1, 2, 1, 1, 2, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predict = np.round(y_test_predict)\n",
    "y_test_predict "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2']}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lreg_clf = LogisticRegression(random_state = 0)\n",
    "\n",
    "param_grid = {'penalty':['l1', 'l2']}\n",
    "\n",
    "grid_search = GridSearchCV(lreg_clf , param_grid, cv = 5 , return_train_score=True)\n",
    "grid_search.fit(X_train_a, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'penalty': 'l1'}"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(penalty = 'l1', random_state = 0).fit(X_train_a, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r2: 0.82312\n",
      "Test r2: 0.85928\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_train_predict = lr_clf.predict(X_train_a)\n",
    "y_test_predict = lr_clf.predict(X_test_a)\n",
    "\n",
    "print('Train r2: {:.5f}'.format(r2_score(y_train, y_train_predict)))\n",
    "print('Test r2: {:.5f}'.format(r2_score(y_test, y_test_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Supprt Vector Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc_clf = SVC(kernel = 'linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To find C for linearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.01, 0.05, 0.1, 0.5, 1, 5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svc = SVC(kernel = 'linear', random_state = 0)\n",
    "param_grid = {'C':[0.01, 0.05, 0.1, 0.5, 1, 5]}\n",
    "\n",
    "grid_search = GridSearchCV(svc, param_grid, cv = 5)\n",
    "grid_search.fit(X_train_a, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters{'C': 5}\n",
      "Best score 0.883681\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters{}'.format(grid_search.best_params_))\n",
    "print('Best score {:.6f}'.format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc_clf = SVC(kernel = 'linear', C=5, random_state = 0).fit(X_train_a, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r2: 0.81271\n",
      "Test r2: 0.84365\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_train_predict = lsvc_clf.predict(X_train_a)\n",
    "y_test_predict = lsvc_clf.predict(X_test_a)\n",
    "\n",
    "print('Train r2: {:.5f}'.format(r2_score(y_train, y_train_predict)))\n",
    "print('Test r2: {:.5f}'.format(r2_score(y_test, y_test_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kerenilzed Support Vector Machine\n",
    "Picked 5 as C and 5 as gamma from the gridsearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_svc = SVC(kernel ='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.01, 0.05, 0.1, 0.5, 1, 5], 'gamma': [0.01, 0.05, 0.1, 1, 5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svc = SVC(kernel = 'rbf', random_state = 0)\n",
    "param_grid = {'C':[0.01, 0.05, 0.1, 0.5, 1, 5], 'gamma':[0.01, 0.05, 0.1, 1, 5]}\n",
    "\n",
    "grid_search = GridSearchCV(svc, param_grid, cv = 5)\n",
    "grid_search.fit(X_train_a, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters{'C': 5, 'gamma': 5}\n",
      "Best score 0.932292\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters{}'.format(grid_search.best_params_))\n",
    "print('Best score {:.6f}'.format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_svc = SVC(kernel = 'rbf', C = 5, gamma = 5, random_state = 0).fit(X_train_a, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r2: 0.97399\n",
      "Test r2: 0.92964\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_train_predict = kernel_svc.predict(X_train_a)\n",
    "y_test_predict = kernel_svc.predict(X_test_a)\n",
    "\n",
    "print('Train r2: {:.5f}'.format(r2_score(y_train, y_train_predict)))\n",
    "print('Test r2: {:.5f}'.format(r2_score(y_test, y_test_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "Picked 7 as the depth from the gridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [1, 3, 5, 7, 10, 15, 20]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision = DecisionTreeClassifier(random_state = 0)\n",
    "param_grid = {'max_depth':[1,3,5,7,10,15,20]}\n",
    "\n",
    "grid_search = GridSearchCV(decision, param_grid, cv = 5)\n",
    "grid_search.fit(X_train_a, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters{'max_depth': 7}\n",
      "Best score 0.953125\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters{}'.format(grid_search.best_params_))\n",
    "print('Best score {:.6f}'.format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc_clf = DecisionTreeClassifier(max_depth = 7, random_state = 0).fit(X_train_a, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r2: 0.96358\n",
      "Test r2: 0.95309\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_train_predict = dtc_clf.predict(X_train_a)\n",
    "y_test_predict = dtc_clf.predict(X_test_a)\n",
    "\n",
    "print('Train r2: {:.5f}'.format(r2_score(y_train, y_train_predict)))\n",
    "print('Test r2: {:.5f}'.format(r2_score(y_test, y_test_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=4, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc_clf = RandomForestClassifier(max_features = 4, random_state = 0)\n",
    "rfc_clf.fit(X_train_a, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r2: 0.99740\n",
      "Test r2: 0.93746\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_train_predict = rfc_clf.predict(X_train_a)\n",
    "y_test_predict = rfc_clf.predict(X_test_a)\n",
    "\n",
    "print('Train r2: {:.5f}'.format(r2_score(y_train, y_train_predict)))\n",
    "print('Test r2: {:.5f}'.format(r2_score(y_test, y_test_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier\n",
    "Hard voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('knn', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scal...         min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best'))],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "lr_clf = LogisticRegression(penalty = 'l1', random_state = 0)\n",
    "lsvc_clf = SVC(kernel = 'linear', C=5, random_state = 0)\n",
    "svc_clf = SVC(kernel = 'rbf', C = 5, gamma = 5, random_state = 0)\n",
    "dtc_clf = DecisionTreeClassifier(max_depth = 7, random_state = 0)\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('knn', knn),('logistic', lr_clf),('linear svc', lsvc_clf),('kernel svc', svc_clf)\n",
    "                                          ,('dtc', dtc_clf)], voting='hard')\n",
    "voting_clf.fit(X_train_a, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier 0.890625\n",
      "LogisticRegression 0.90625\n",
      "SVC 0.895833333333\n",
      "SVC 0.953125\n",
      "DecisionTreeClassifier 0.96875\n",
      "VotingClassifier 0.932291666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (knn, lr_clf, lsvc_clf, svc_clf, dtc_clf, voting_clf):\n",
    "    clf.fit(X_train_a, y_train)\n",
    "    y_pred = clf.predict(X_test_a)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r2: 0.93237\n",
      "Test r2: 0.89837\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_train_predict = voting_clf.predict(X_train_a)\n",
    "y_test_predict = voting_clf.predict(X_test_a)\n",
    "\n",
    "print('Train r2: {:.5f}'.format(r2_score(y_train, y_train_predict)))\n",
    "print('Test r2: {:.5f}'.format(r2_score(y_test, y_test_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 3 1 3 2 2 3 2 2 1 3 1 3 3 2 1 2 1 1 1 3 1 3 1 1 1 1 1 3 1 1 3 1 2 3 1\n",
      " 3 1 1 1 3 1 2 2 2 1 1 2 2 3 1 3 1 3 1 2 2 3 1 1 1 3 1 1 1 3 1 2 3 3 1 2 1\n",
      " 1 2 3 3 3 1 3 2 1 1 3 2 2 3 1 1 1 2 1 2 3 1 2 1 1 3 2 2 2 3 1 2 3 1 1 2 1\n",
      " 3 2 1 1 1 1 3 2 3 3 1 1 3 1 3 1 2 1 2 3 2 2 1 3 1 2 2 3 1 1 1 2 1 3 1 2 3\n",
      " 1 1 2 1 1 1 1 3 2 2 1 2 3 1 2 3 1 1 1 2 1 2 3 1 2 3 3 2 2 2 1 2 1 3 2 1 1\n",
      " 2 1 1 2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(voting_clf.predict(X_test_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('knn', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scal...         min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best'))],\n",
       "         flatten_transform=None, n_jobs=1, voting='soft', weights=None)"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "lr_clf = LogisticRegression(penalty = 'l1', random_state = 0)\n",
    "lsvc_clf = SVC(kernel = 'linear',probability=True, C=5, random_state = 0)\n",
    "svc_clf = SVC(kernel = 'rbf', C = 5,probability=True, gamma = 5, random_state = 0)\n",
    "dtc_clf = DecisionTreeClassifier(max_depth = 7, random_state = 0)\n",
    "\n",
    "voting_clf_soft = VotingClassifier(estimators=[('knn', knn),('logistic', lr_clf),('linear svc', lsvc_clf),('kernel svc', svc_clf)\n",
    "                                          ,('dtc', dtc_clf)], voting='soft')\n",
    "voting_clf_soft.fit(X_train_a, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier 0.890625\n",
      "LogisticRegression 0.90625\n",
      "SVC 0.895833333333\n",
      "SVC 0.953125\n",
      "DecisionTreeClassifier 0.96875\n",
      "VotingClassifier 0.942708333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (knn, lr_clf, lsvc_clf, svc_clf, dtc_clf, voting_clf_soft):\n",
    "    clf.fit(X_train_a, y_train)\n",
    "    y_pred = clf.predict(X_test_a)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r2: 0.93237\n",
      "Test r2: 0.89837\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_train_predict = voting_clf.predict(X_train_a)\n",
    "y_test_predict = voting_clf.predict(X_test_a)\n",
    "\n",
    "print('Train r2: {:.5f}'.format(r2_score(y_train, y_train_predict)))\n",
    "print('Test r2: {:.5f}'.format(r2_score(y_test, y_test_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 3 1 3 2 2 3 2 2 1 3 1 3 3 2 1 2 1 1 1 3 1 3 1 1 1 1 1 3 1 1 3 1 2 3 1\n",
      " 3 1 1 1 3 1 2 2 2 1 1 2 2 3 1 3 1 3 1 2 2 3 1 1 1 3 1 1 1 3 1 2 3 3 1 2 1\n",
      " 1 2 3 3 3 1 3 2 1 1 3 2 2 3 1 1 1 2 1 2 3 1 2 1 1 3 2 2 2 3 1 2 3 1 1 2 1\n",
      " 3 2 1 1 1 1 3 2 3 3 1 1 3 1 3 1 2 1 2 3 2 2 1 3 1 2 2 3 1 1 1 2 1 3 1 2 3\n",
      " 1 1 2 1 1 1 1 3 2 2 1 2 3 1 2 3 1 1 1 2 1 2 3 1 2 3 3 2 2 2 1 2 1 3 2 1 1\n",
      " 2 1 1 2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(voting_clf.predict(X_test_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply on Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=100, n_estimators=500, n_jobs=-1, oob_score=False,\n",
       "         random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_logi = BaggingClassifier(LogisticRegression(penalty = 'l1'), n_estimators=500, max_samples=100, bootstrap=True, n_jobs=-1, random_state=0)\n",
    "bag_logi.fit(X_train_a, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r2: 0.79971\n",
      "Test r2: 0.85147\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_train_predict = bag_logi.predict(X_train_a)\n",
    "y_test_predict = bag_logi.predict(X_test_a)\n",
    "\n",
    "print('Train r2: {:.5f}'.format(r2_score(y_train, y_train_predict)))\n",
    "print('Test r2: {:.5f}'.format(r2_score(y_test, y_test_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply on linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=SVC(C=5, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=100, n_estimators=500, n_jobs=-1, oob_score=False,\n",
       "         random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_svcl = BaggingClassifier(SVC(kernel = 'linear', C=5, probability=True), n_estimators=500, max_samples=100, bootstrap=True, n_jobs=-1, random_state=0)\n",
    "bag_svcl.fit(X_train_a, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r2: 0.81792\n",
      "Test r2: 0.85928\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_train_predict = bag_svcl.predict(X_train_a)\n",
    "y_test_predict = bag_svcl.predict(X_test_a)\n",
    "\n",
    "print('Train r2: {:.5f}'.format(r2_score(y_train, y_train_predict)))\n",
    "print('Test r2: {:.5f}'.format(r2_score(y_test, y_test_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply on Kernelized SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=SVC(C=5, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=5, kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=100, n_estimators=500, n_jobs=-1, oob_score=False,\n",
       "         random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_svckbf =  BaggingClassifier(SVC(kernel = 'rbf', C = 5,probability=True, gamma = 5), n_estimators=500, max_samples=100, bootstrap=True, n_jobs=-1, random_state=0)\n",
    "bag_svckbf.fit(X_train_a, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r2: 0.92977\n",
      "Test r2: 0.88274\n"
     ]
    }
   ],
   "source": [
    "y_train_predict = bag_svckbf.predict(X_train_a)\n",
    "y_test_predict = bag_svckbf.predict(X_test_a)\n",
    "\n",
    "print('Train r2: {:.5f}'.format(r2_score(y_train, y_train_predict)))\n",
    "print('Test r2: {:.5f}'.format(r2_score(y_test, y_test_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply on Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=15,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=100, n_estimators=500, n_jobs=-1, oob_score=False,\n",
       "         random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_decision =  BaggingClassifier(DecisionTreeClassifier(max_depth = 15), n_estimators=500, max_samples=100, bootstrap=True, n_jobs=-1, random_state=0)\n",
    "bag_decision.fit(X_train_a, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r2: 0.94277\n",
      "Test r2: 0.90619\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_train_predict = bag_decision.predict(X_train_a)\n",
    "y_test_predict = bag_decision.predict(X_test_a)\n",
    "\n",
    "print('Train r2: {:.5f}'.format(r2_score(y_train, y_train_predict)))\n",
    "print('Test r2: {:.5f}'.format(r2_score(y_test, y_test_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-Bag evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply on Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87326388888888884"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_out_logi = BaggingClassifier(\n",
    "    LogisticRegression(penalty = 'l1'),n_estimators=500,\n",
    "    bootstrap=True, n_jobs=-1, oob_score=True, random_state=0)\n",
    "bag_out_logi.fit(X_train_a, y_train)\n",
    "bag_out_logi.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r2: 0.82572\n",
      "Test r2: 0.87492\n"
     ]
    }
   ],
   "source": [
    "y_train_predict = bag_out_logi.predict(X_train_a)\n",
    "y_test_predict = bag_out_logi.predict(X_test_a)\n",
    "\n",
    "print('Train r2: {:.5f}'.format(r2_score(y_train, y_train_predict)))\n",
    "print('Test r2: {:.5f}'.format(r2_score(y_test, y_test_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply on Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87673611111111116"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_out_svcl = BaggingClassifier(\n",
    "    SVC(kernel = 'linear', C=5), n_estimators=500,\n",
    "    bootstrap=True, n_jobs=-1, oob_score=True, random_state=0)\n",
    "bag_out_svcl.fit(X_train_a, y_train)\n",
    "bag_out_svcl.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r2: 0.82832\n",
      "Test r2: 0.85147\n"
     ]
    }
   ],
   "source": [
    "y_train_predict = bag_out_svcl.predict(X_train_a)\n",
    "y_test_predict = bag_out_svcl.predict(X_test_a)\n",
    "\n",
    "print('Train r2: {:.5f}'.format(r2_score(y_train, y_train_predict)))\n",
    "print('Test r2: {:.5f}'.format(r2_score(y_test, y_test_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply on Kernelized SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93229166666666663"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_out_svckbf = BaggingClassifier(\n",
    "    SVC(kernel = 'rbf', C = 5, gamma = 5), n_estimators=500,\n",
    "    bootstrap=True, n_jobs=-1, oob_score=True, random_state=0)\n",
    "bag_out_svckbf.fit(X_train_a, y_train)\n",
    "bag_out_svckbf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r2: 0.98179\n",
      "Test r2: 0.92964\n"
     ]
    }
   ],
   "source": [
    "y_train_predict = bag_out_svckbf.predict(X_train_a)\n",
    "y_test_predict = bag_out_svckbf.predict(X_test_a)\n",
    "\n",
    "print('Train r2: {:.5f}'.format(r2_score(y_train, y_train_predict)))\n",
    "print('Test r2: {:.5f}'.format(r2_score(y_test, y_test_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply on Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95659722222222221"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_out_decision = BaggingClassifier(\n",
    "    DecisionTreeClassifier(max_depth = 7), n_estimators=500,\n",
    "    bootstrap=True, n_jobs=-1, oob_score=True, random_state=0)\n",
    "bag_out_decision.fit(X_train_a, y_train)\n",
    "bag_out_decision.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r2: 0.97139\n",
      "Test r2: 0.93746\n"
     ]
    }
   ],
   "source": [
    "y_train_predict = bag_out_decision.predict(X_train_a)\n",
    "y_test_predict = bag_out_decision.predict(X_test_a)\n",
    "\n",
    "print('Train r2: {:.5f}'.format(r2_score(y_train, y_train_predict)))\n",
    "print('Test r2: {:.5f}'.format(r2_score(y_test, y_test_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply on Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "          learning_rate=0.5, n_estimators=200, random_state=0)"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf_Lo = AdaBoostClassifier(\n",
    "    LogisticRegression(penalty = 'l1'), n_estimators=200,\n",
    "    algorithm=\"SAMME.R\", learning_rate=0.5, random_state=0)\n",
    "ada_clf_Lo.fit(X_train_a, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r2: -0.77402\n",
      "Test r2: -0.89186\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_train_predict = ada_clf_Lo.predict(X_train_a)\n",
    "y_test_predict = ada_clf_Lo.predict(X_test_a)\n",
    "\n",
    "print('Train r2: {:.5f}'.format(r2_score(y_train, y_train_predict)))\n",
    "print('Test r2: {:.5f}'.format(r2_score(y_test, y_test_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.513888888889\n",
      "0.473958333333\n"
     ]
    }
   ],
   "source": [
    "print(ada_clf_Lo.score(X_train_a, y_train))\n",
    "print(ada_clf_Lo.score(X_test_a, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_clf_Lo.predict(X_test_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply on Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=SVC(C=5, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=True, random_state=0, shrinking=True, tol=0.001,\n",
       "  verbose=False),\n",
       "          learning_rate=0.5, n_estimators=200, random_state=42)"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_clf_svcl = AdaBoostClassifier(n_estimators=200, base_estimator=SVC(kernel = 'linear', C=5, probability=True, random_state=0),\n",
    "                   algorithm=\"SAMME.R\", learning_rate=0.5, random_state=42)\n",
    "ada_clf_svcl.fit(X_train_a, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r2: 0.62803\n",
      "Test r2: 0.60130\n"
     ]
    }
   ],
   "source": [
    "y_train_predict = ada_clf_svcl.predict(X_train_a)\n",
    "y_test_predict = ada_clf_svcl.predict(X_test_a)\n",
    "\n",
    "print('Train r2: {:.5f}'.format(r2_score(y_train, y_train_predict)))\n",
    "print('Test r2: {:.5f}'.format(r2_score(y_test, y_test_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.751736111111\n",
      "0.734375\n"
     ]
    }
   ],
   "source": [
    "print(ada_clf_svcl.score(X_train_a, y_train))\n",
    "print(ada_clf_svcl.score(X_test_a, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1,\n",
       "       2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2,\n",
       "       1, 1, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2,\n",
       "       2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 2,\n",
       "       1, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1,\n",
       "       1, 1, 2, 2, 2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 2,\n",
       "       2, 1, 1, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 2, 2,\n",
       "       1, 2, 2, 1, 1, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1,\n",
       "       1, 2, 1, 1, 2, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_clf_svcl.predict(X_test_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply on Kernelized SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=SVC(C=5, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=5, kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=42, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "          learning_rate=0.5, n_estimators=200, random_state=0)"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf_svcrbf = AdaBoostClassifier(\n",
    "    SVC(probability=True, kernel = 'rbf', C = 5, gamma = 5, random_state=42), n_estimators=200,\n",
    "    algorithm=\"SAMME.R\", learning_rate=0.5, random_state=0)\n",
    "ada_clf_svcrbf.fit(X_train_a, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r2: -0.52430\n",
      "Test r2: -0.76678\n"
     ]
    }
   ],
   "source": [
    "y_train_predict = ada_clf_svcrbf.predict(X_train_a)\n",
    "y_test_predict = ada_clf_svcrbf.predict(X_test_a)\n",
    "\n",
    "print('Train r2: {:.5f}'.format(r2_score(y_train, y_train_predict)))\n",
    "print('Test r2: {:.5f}'.format(r2_score(y_test, y_test_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.555555555556\n",
      "0.494791666667\n"
     ]
    }
   ],
   "source": [
    "print(ada_clf_svcrbf.score(X_train_a, y_train))\n",
    "print(ada_clf_svcrbf.score(X_test_a, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_clf_svcrbf.predict(X_test_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply on Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=15,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=0.5, n_estimators=200, random_state=0)"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf_decision = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=15), n_estimators=200,\n",
    "    algorithm=\"SAMME.R\", learning_rate=0.5, random_state=0)\n",
    "ada_clf_decision.fit(X_train_a, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r2: 1.00000\n",
      "Test r2: 0.96091\n"
     ]
    }
   ],
   "source": [
    "y_train_predict = ada_clf_decision.predict(X_train_a)\n",
    "y_test_predict = ada_clf_decision.predict(X_test_a)\n",
    "\n",
    "print('Train r2: {:.5f}'.format(r2_score(y_train, y_train_predict)))\n",
    "print('Test r2: {:.5f}'.format(r2_score(y_test, y_test_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.973958333333\n"
     ]
    }
   ],
   "source": [
    "print(ada_clf_decision.score(X_train_a, y_train))\n",
    "print(ada_clf_decision.score(X_test_a, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 3, 1, 3, 2, 2, 2, 2, 2, 1, 3, 1, 3, 3, 2, 1, 2, 1, 1, 1, 3, 1,\n",
       "       3, 1, 1, 1, 1, 1, 3, 1, 1, 3, 1, 2, 3, 1, 3, 1, 1, 1, 3, 1, 2, 2, 2,\n",
       "       1, 1, 2, 2, 3, 1, 3, 1, 3, 1, 1, 2, 3, 1, 1, 1, 3, 1, 1, 1, 3, 1, 2,\n",
       "       3, 3, 1, 2, 1, 1, 2, 3, 3, 3, 1, 3, 2, 1, 1, 2, 2, 2, 3, 1, 1, 1, 2,\n",
       "       1, 2, 3, 1, 2, 1, 1, 3, 3, 2, 2, 3, 1, 2, 3, 1, 1, 1, 1, 3, 2, 1, 1,\n",
       "       1, 1, 3, 2, 3, 3, 1, 1, 3, 1, 3, 1, 2, 1, 2, 3, 2, 3, 1, 3, 1, 2, 2,\n",
       "       3, 1, 1, 2, 2, 1, 3, 1, 2, 3, 1, 1, 2, 1, 1, 1, 1, 3, 2, 2, 1, 2, 3,\n",
       "       1, 2, 2, 1, 1, 1, 3, 1, 2, 3, 1, 3, 3, 3, 2, 2, 2, 1, 2, 1, 3, 2, 1,\n",
       "       1, 2, 1, 1, 2, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_clf_decision.predict(X_test_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "params = {'n_estimators': 500, 'max_depth': 7,\n",
    "        'learning_rate': 0.1, 'loss': 'huber','alpha':0.95}\n",
    "clf = GradientBoostingRegressor(**params).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.8536\n",
      "R2: -0.2813\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, clf.predict(X_test_a))\n",
    "r2 = r2_score(y_test, clf.predict(X_test_a))\n",
    "\n",
    "print(\"MSE: %.4f\" % mse)\n",
    "print(\"R2: %.4f\" % r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply to Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc_clf1 = DecisionTreeClassifier(max_depth = 7)\n",
    "dtc_clf1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = y - dtc_clf1.predict(X)\n",
    "dtc_clf2 = DecisionTreeClassifier(max_depth = 7)\n",
    "dtc_clf2.fit(X, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3= y2 - dtc_clf2.predict(X)\n",
    "dtc_clf3 = DecisionTreeClassifier(max_depth = 7)\n",
    "dtc_clf3.fit(X, y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r2: -4.15038\n",
      "Test r2: -4.34723\n"
     ]
    }
   ],
   "source": [
    "y_train_predict = dtc_clf3.predict(X_train_a)\n",
    "y_test_predict = dtc_clf3.predict(X_test_a)\n",
    "\n",
    "print('Train r2: {:.5f}'.format(r2_score(y_train, y_train_predict)))\n",
    "print('Test r2: {:.5f}'.format(r2_score(y_test, y_test_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98046875"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dtc_clf.score(X, y) for dtc_clf in (dtc_clf1, dtc_clf2, dtc_clf3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 3, 2, 2, 3, 2, 2, 2,\n",
       "       2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 2, 3, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 2, 3, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2,\n",
       "       2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2,\n",
       "       2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3,\n",
       "       2, 2, 2, 3, 3, 3, 3, 3, 2, 2, 3, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1,\n",
       "       1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 3, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 3, 2, 2, 2, 2, 2, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 2, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 3, 3, 2, 2, 2, 2,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = sum(dtc_clf.predict(X) for dtc_clf in (dtc_clf1, dtc_clf2, dtc_clf3))\n",
    "y_pred.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "After running classification models, I figured out that decision tree is the best model because it has high R2 score and the difference between the training data set and the test data set is not big as other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the neural network to get a better model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "\n",
    "numpy.random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 - Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_787 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_788 (Dense)            (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_789 (Dense)            (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 133\n",
      "Trainable params: 133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=8, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(6, kernel_initializer = 'normal', activation = 'relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2- Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3- Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "576/576 [==============================] - 8s 14ms/step - loss: 0.9633 - acc: 0.2396\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.6241 - acc: 0.3837\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.2894 - acc: 0.6719\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.1986 - acc: 0.7500\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.2174 - acc: 0.7378\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.1874 - acc: 0.7813\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.1844 - acc: 0.7604\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.1781 - acc: 0.7882\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.2108 - acc: 0.7500\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.1712 - acc: 0.7882\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.1770 - acc: 0.7656\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.1715 - acc: 0.7813\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.1785 - acc: 0.7674\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.1746 - acc: 0.7622\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.1660 - acc: 0.7951\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.1640 - acc: 0.7951\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.1683 - acc: 0.8056\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.1593 - acc: 0.7969\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.1566 - acc: 0.7986\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.1481 - acc: 0.8142\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.1622 - acc: 0.8073\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.1482 - acc: 0.8142\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.1473 - acc: 0.8160\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.1403 - acc: 0.8264\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.1381 - acc: 0.8142\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.1415 - acc: 0.8264\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.1434 - acc: 0.8108\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.1356 - acc: 0.8142\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.1391 - acc: 0.8438\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.1324 - acc: 0.8229\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.1206 - acc: 0.8438\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.1182 - acc: 0.8333\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.1157 - acc: 0.8385A: 0s - loss: 0.1170 - acc: \n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.1149 - acc: 0.8594\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.1127 - acc: 0.8542\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.1262 - acc: 0.8455\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.1121 - acc: 0.8472\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.1149 - acc: 0.8420\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.1134 - acc: 0.8403\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.1112 - acc: 0.8542\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.1167 - acc: 0.8333\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.1193 - acc: 0.8594\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.1078 - acc: 0.8576\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.1112 - acc: 0.8524\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.1041 - acc: 0.8663\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.1081 - acc: 0.8663A: 0s - loss: 0.1140 - acc: 0.\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.1072 - acc: 0.8438\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.1156 - acc: 0.8385\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.1138 - acc: 0.8490\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.1134 - acc: 0.8472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a164139470>"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, batch_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search for finding epochs and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x000002A134C6DB00>,\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'epochs': [50, 100, 150, 200], 'batch_size': [5, 10, 20, 50, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=8, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(6, kernel_initializer = 'normal', activation = 'relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "param_grid = {'epochs':[50, 100, 150, 200] , 'batch_size':[5,10,20, 50, 100]}\n",
    "\n",
    "keras_classifier = KerasClassifier(build_fn = create_model , verbose = 0)\n",
    "\n",
    "grid_search = GridSearchCV(keras_classifier , param_grid , cv =5)\n",
    "\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters{'batch_size': 5, 'epochs': 50}\n",
      "Best score 0.881944\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters{}'.format(grid_search.best_params_))\n",
    "print('Best score {:.6f}'.format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 - Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r2: 0.85062\n",
      "Test r2: 0.84477\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_train_predict = model.predict(X_train)\n",
    "y_test_predict = model.predict(X_test)\n",
    "\n",
    "print('Train r2: {:.5f}'.format(r2_score(y_train, y_train_predict)))\n",
    "print('Test r2: {:.5f}'.format(r2_score(y_test, y_test_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5- Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00927162],\n",
       "       [ 0.96055865],\n",
       "       [ 2.43221688],\n",
       "       [ 2.08505869],\n",
       "       [ 2.25593257],\n",
       "       [ 2.38943887],\n",
       "       [ 2.28662634],\n",
       "       [ 2.16405129],\n",
       "       [ 2.01054215],\n",
       "       [ 2.19898796],\n",
       "       [ 0.97020614],\n",
       "       [ 2.44962001],\n",
       "       [ 1.01262069],\n",
       "       [ 2.4645524 ],\n",
       "       [ 2.55724406],\n",
       "       [ 1.99123752],\n",
       "       [ 0.97903752],\n",
       "       [ 2.35854197],\n",
       "       [ 1.04199934],\n",
       "       [ 0.97566521],\n",
       "       [ 0.99303329],\n",
       "       [ 2.28682971],\n",
       "       [ 0.97564209],\n",
       "       [ 2.42094851],\n",
       "       [ 0.95705163],\n",
       "       [ 0.97724688],\n",
       "       [ 1.04041791],\n",
       "       [ 0.96952879],\n",
       "       [ 0.97365701],\n",
       "       [ 2.52511144],\n",
       "       [ 1.04084456],\n",
       "       [ 1.00882185],\n",
       "       [ 2.4794848 ],\n",
       "       [ 1.00613165],\n",
       "       [ 2.30155897],\n",
       "       [ 2.91605186],\n",
       "       [ 0.9641484 ],\n",
       "       [ 2.97784615],\n",
       "       [ 1.03551042],\n",
       "       [ 1.0105294 ],\n",
       "       [ 1.00610852],\n",
       "       [ 2.46434903],\n",
       "       [ 0.99149787],\n",
       "       [ 2.29183888],\n",
       "       [ 1.73021615],\n",
       "       [ 2.28539133],\n",
       "       [ 0.98441792],\n",
       "       [ 0.99529684],\n",
       "       [ 2.43526888],\n",
       "       [ 2.0784111 ],\n",
       "       [ 2.30279422],\n",
       "       [ 1.03390563],\n",
       "       [ 2.97867489],\n",
       "       [ 1.01352036],\n",
       "       [ 2.94694901],\n",
       "       [ 0.95915604],\n",
       "       [ 2.18192124],\n",
       "       [ 2.20650125],\n",
       "       [ 2.54210782],\n",
       "       [ 0.99843681],\n",
       "       [ 1.01040339],\n",
       "       [ 0.97453356],\n",
       "       [ 2.33369136],\n",
       "       [ 0.96862924],\n",
       "       [ 0.97297513],\n",
       "       [ 0.96256685],\n",
       "       [ 2.48031378],\n",
       "       [ 0.99570036],\n",
       "       [ 2.03390622],\n",
       "       [ 2.51121116],\n",
       "       [ 2.30176234],\n",
       "       [ 0.98059595],\n",
       "       [ 2.27842975],\n",
       "       [ 1.03706872],\n",
       "       [ 1.02574003],\n",
       "       [ 2.24916983],\n",
       "       [ 2.33265924],\n",
       "       [ 2.5730052 ],\n",
       "       [ 2.36355662],\n",
       "       [ 0.97342479],\n",
       "       [ 2.42177486],\n",
       "       [ 2.4043715 ],\n",
       "       [ 1.00072813],\n",
       "       [ 1.04434168],\n",
       "       [ 2.40237665],\n",
       "       [ 2.21239686],\n",
       "       [ 2.36315012],\n",
       "       [ 2.36715627],\n",
       "       [ 1.03702259],\n",
       "       [ 1.03820062],\n",
       "       [ 0.96372175],\n",
       "       [ 2.07067943],\n",
       "       [ 0.95903134],\n",
       "       [ 2.23956156],\n",
       "       [ 2.87042546],\n",
       "       [ 1.03211498],\n",
       "       [ 2.28026605],\n",
       "       [ 0.99079287],\n",
       "       [ 0.99924707],\n",
       "       [ 2.94798112],\n",
       "       [ 2.47907853],\n",
       "       [ 2.15631938],\n",
       "       [ 1.80376232],\n",
       "       [ 2.8380897 ],\n",
       "       [ 0.96976101],\n",
       "       [ 2.05321074],\n",
       "       [ 2.54127932],\n",
       "       [ 1.01264381],\n",
       "       [ 0.97184324],\n",
       "       [ 2.19788575],\n",
       "       [ 1.02819812],\n",
       "       [ 2.96271038],\n",
       "       [ 1.95630062],\n",
       "       [ 1.02304995],\n",
       "       [ 0.98061907],\n",
       "       [ 1.02843022],\n",
       "       [ 1.01375246],\n",
       "       [ 2.54087281],\n",
       "       [ 1.99713337],\n",
       "       [ 2.99401402],\n",
       "       [ 2.48253703],\n",
       "       [ 0.96214008],\n",
       "       [ 0.97410679],\n",
       "       [ 2.40581012],\n",
       "       [ 0.97835541],\n",
       "       [ 2.9950459 ],\n",
       "       [ 0.96910214],\n",
       "       [ 2.31752372],\n",
       "       [ 0.96525705],\n",
       "       [ 2.01076102],\n",
       "       [ 2.88598323],\n",
       "       [ 2.22359705],\n",
       "       [ 2.50997567],\n",
       "       [ 0.96369863],\n",
       "       [ 3.02573991],\n",
       "       [ 0.99698341],\n",
       "       [ 2.35970783],\n",
       "       [ 2.2076323 ],\n",
       "       [ 2.97764277],\n",
       "       [ 0.97993696],\n",
       "       [ 1.01925099],\n",
       "       [ 1.01743722],\n",
       "       [ 2.40333962],\n",
       "       [ 0.97077489],\n",
       "       [ 2.35307932],\n",
       "       [ 1.04089081],\n",
       "       [ 2.3106482 ],\n",
       "       [ 2.8861866 ],\n",
       "       [ 0.99190152],\n",
       "       [ 1.03860414],\n",
       "       [ 2.379318  ],\n",
       "       [ 1.00993049],\n",
       "       [ 1.04739618],\n",
       "       [ 1.03322363],\n",
       "       [ 0.96485353],\n",
       "       [ 2.90091586],\n",
       "       [ 2.48213077],\n",
       "       [ 2.19309235],\n",
       "       [ 1.0092485 ],\n",
       "       [ 2.31628823],\n",
       "       [ 2.43345213],\n",
       "       [ 0.97523856],\n",
       "       [ 2.25449395],\n",
       "       [ 2.27189708],\n",
       "       [ 1.00457323],\n",
       "       [ 1.02352273],\n",
       "       [ 1.01420224],\n",
       "       [ 1.9254235 ],\n",
       "       [ 1.04129434],\n",
       "       [ 1.8400861 ],\n",
       "       [ 2.91728711],\n",
       "       [ 0.9821775 ],\n",
       "       [ 2.33038354],\n",
       "       [ 2.58917284],\n",
       "       [ 3.00957227],\n",
       "       [ 2.34718561],\n",
       "       [ 1.85755432],\n",
       "       [ 2.16972804],\n",
       "       [ 0.99617326],\n",
       "       [ 2.33122087],\n",
       "       [ 0.96324885],\n",
       "       [ 2.55827594],\n",
       "       [ 2.05910659],\n",
       "       [ 1.02633905],\n",
       "       [ 0.98644924],\n",
       "       [ 2.14452791],\n",
       "       [ 0.97252524],\n",
       "       [ 0.97679698],\n",
       "       [ 2.13295531],\n",
       "       [ 1.03548717],\n",
       "       [ 1.03164208],\n",
       "       [ 0.98330927]], dtype=float32)"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = model.predict(X_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a17d8781d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig = plt.figure(facecolor='w')\n",
    "ax = fig.add_axes([0, 0, 2, 2],\n",
    "                  xticks=[], yticks=[])\n",
    "plt.box(False)\n",
    "circ = plt.Circle((1, 1), 2)\n",
    "\n",
    "radius = 0.2\n",
    "\n",
    "arrow_kwargs = dict(head_width=0.05, fc='black')\n",
    "\n",
    "\n",
    "# function to draw arrows\n",
    "def draw_connecting_arrow(ax, circ1, rad1, circ2, rad2):\n",
    "    theta = np.arctan2(circ2[1] - circ1[1],\n",
    "                       circ2[0] - circ1[0])\n",
    "\n",
    "    starting_point = (circ1[0] + rad1 * np.cos(theta),\n",
    "                      circ1[1] + rad1 * np.sin(theta))\n",
    "\n",
    "    length = (circ2[0] - circ1[0] - (rad1 + 1.4 * rad2) * np.cos(theta),\n",
    "              circ2[1] - circ1[1] - (rad1 + 1.4 * rad2) * np.sin(theta))\n",
    "\n",
    "    ax.arrow(starting_point[0], starting_point[1],\n",
    "             length[0], length[1], **arrow_kwargs)\n",
    "\n",
    "\n",
    "# function to draw circles\n",
    "def draw_circle(ax, center, radius):\n",
    "    circ = plt.Circle(center, radius, fc='black', lw=2)\n",
    "    ax.add_patch(circ)\n",
    "\n",
    "x1 = -2\n",
    "x2 = 0\n",
    "x3 = 2\n",
    "y3 = 0\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# draw circles\n",
    "for i, y1 in enumerate(np.linspace(1.5, -1.5, 8)):\n",
    "    draw_circle(ax, (x1, y1), radius)\n",
    "    ax.text(x1 - 0.9, y1, 'Input #%i' % (i + 1),\n",
    "            ha='right', va='center', fontsize=16)\n",
    "    draw_connecting_arrow(ax, (x1 - 0.9, y1), 0.1, (x1, y1), radius)\n",
    "\n",
    "for y2 in np.linspace(-2, 2, 6):\n",
    "    draw_circle(ax, (x2, y2), radius)\n",
    "\n",
    "draw_circle(ax, (x3, y3), radius)\n",
    "ax.text(x3 + 0.8, y3, 'Output', ha='left', va='center', fontsize=16)\n",
    "draw_connecting_arrow(ax, (x3, y3), radius, (x3 + 0.8, y3), 0.1)\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# draw connecting arrows\n",
    "for y1 in np.linspace(-1.5, 1.5, 6):\n",
    "    for y2 in np.linspace(-2, 2, 6):\n",
    "        draw_connecting_arrow(ax, (x1, y1), radius, (x2, y2), radius)\n",
    "\n",
    "for y2 in np.linspace(-2, 2, 6):\n",
    "    draw_connecting_arrow(ax, (x2, y2), radius, (x3, y3), radius)\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Add text labels\n",
    "plt.text(x1, 2.7, \"Input\\nLayer\", ha='center', va='top', fontsize=16)\n",
    "plt.text(x2, 2.7, \"Hidden Layer\", ha='center', va='top', fontsize=16)\n",
    "plt.text(x3, 2.7, \"Output\\nLayer\", ha='center', va='top', fontsize=16)\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "plt.xlim(-3, 3)\n",
    "plt.ylim(-3, 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 3.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 3.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 3.],\n",
       "       [ 1.],\n",
       "       [ 3.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 3.],\n",
       "       [ 1.],\n",
       "       [ 3.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 3.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 3.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 3.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 3.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 3.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 3.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 3.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 3.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 3.],\n",
       "       [ 2.],\n",
       "       [ 3.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 3.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 3.],\n",
       "       [ 2.],\n",
       "       [ 3.],\n",
       "       [ 1.],\n",
       "       [ 3.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 3.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 3.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 3.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 3.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 3.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.]], dtype=float32)"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = np.round(y_predict)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change number to string to make it easy to recognize the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>New_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.66</td>\n",
       "      <td>759.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.40</td>\n",
       "      <td>3</td>\n",
       "      <td>High Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.74</td>\n",
       "      <td>686.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2</td>\n",
       "      <td>High Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.79</td>\n",
       "      <td>637.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2</td>\n",
       "      <td>Avg Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.82</td>\n",
       "      <td>612.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>Avg Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "      <td>Avg Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2</td>\n",
       "      <td>Avg Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "      <td>Avg Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.82</td>\n",
       "      <td>612.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2</td>\n",
       "      <td>Avg Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.86</td>\n",
       "      <td>588.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>Avg Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.82</td>\n",
       "      <td>612.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>4</td>\n",
       "      <td>Avg Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.71</td>\n",
       "      <td>710.5</td>\n",
       "      <td>269.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>High Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.79</td>\n",
       "      <td>637.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "      <td>Avg Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.66</td>\n",
       "      <td>759.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>High Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.79</td>\n",
       "      <td>637.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2</td>\n",
       "      <td>Avg Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.79</td>\n",
       "      <td>637.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.40</td>\n",
       "      <td>5</td>\n",
       "      <td>Low Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.86</td>\n",
       "      <td>588.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>4</td>\n",
       "      <td>Avg Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.71</td>\n",
       "      <td>710.5</td>\n",
       "      <td>269.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>High Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>Avg Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>High Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.71</td>\n",
       "      <td>710.5</td>\n",
       "      <td>269.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "      <td>High Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.69</td>\n",
       "      <td>735.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>High Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2</td>\n",
       "      <td>Avg Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.71</td>\n",
       "      <td>710.5</td>\n",
       "      <td>269.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>High Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.79</td>\n",
       "      <td>637.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "      <td>Avg Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.74</td>\n",
       "      <td>686.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>High Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.71</td>\n",
       "      <td>710.5</td>\n",
       "      <td>269.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2</td>\n",
       "      <td>High Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>4</td>\n",
       "      <td>High Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.74</td>\n",
       "      <td>686.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.40</td>\n",
       "      <td>5</td>\n",
       "      <td>High Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.71</td>\n",
       "      <td>710.5</td>\n",
       "      <td>269.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>High Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.79</td>\n",
       "      <td>637.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "      <td>Low Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2</td>\n",
       "      <td>Avg Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "      <td>Avg Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.66</td>\n",
       "      <td>759.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>High Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.64</td>\n",
       "      <td>784.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2</td>\n",
       "      <td>High Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.66</td>\n",
       "      <td>759.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "      <td>High Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.86</td>\n",
       "      <td>588.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.40</td>\n",
       "      <td>3</td>\n",
       "      <td>Avg Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "      <td>High Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.86</td>\n",
       "      <td>588.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "      <td>Avg Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.76</td>\n",
       "      <td>661.5</td>\n",
       "      <td>416.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2</td>\n",
       "      <td>Low Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.71</td>\n",
       "      <td>710.5</td>\n",
       "      <td>269.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>High Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.79</td>\n",
       "      <td>637.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>Avg Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.79</td>\n",
       "      <td>637.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.40</td>\n",
       "      <td>5</td>\n",
       "      <td>Low Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.76</td>\n",
       "      <td>661.5</td>\n",
       "      <td>416.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>Low Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>Avg Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.86</td>\n",
       "      <td>588.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "      <td>Avg Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.82</td>\n",
       "      <td>612.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>Avg Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.69</td>\n",
       "      <td>735.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.40</td>\n",
       "      <td>4</td>\n",
       "      <td>High Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>Avg Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.74</td>\n",
       "      <td>686.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>High Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.79</td>\n",
       "      <td>637.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.40</td>\n",
       "      <td>4</td>\n",
       "      <td>Low Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.86</td>\n",
       "      <td>588.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "      <td>Avg Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>High Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.71</td>\n",
       "      <td>710.5</td>\n",
       "      <td>269.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>5</td>\n",
       "      <td>High Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.82</td>\n",
       "      <td>612.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>Avg Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.71</td>\n",
       "      <td>710.5</td>\n",
       "      <td>269.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>High Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.71</td>\n",
       "      <td>710.5</td>\n",
       "      <td>269.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "      <td>High Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.82</td>\n",
       "      <td>612.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>Avg Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "      <td>High Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2</td>\n",
       "      <td>High Efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.71</td>\n",
       "      <td>710.5</td>\n",
       "      <td>269.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>High Efficiency</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       X1     X2     X3      X4   X5  X6    X7  X8            New_y\n",
       "0    0.66  759.5  318.5  220.50  3.5   3  0.40   3  High Efficiency\n",
       "1    0.74  686.0  245.0  220.50  3.5   4  0.10   2  High Efficiency\n",
       "2    0.79  637.0  343.0  147.00  7.0   3  0.10   2   Avg Efficiency\n",
       "3    0.82  612.5  318.5  147.00  7.0   4  0.00   0   Avg Efficiency\n",
       "4    0.98  514.5  294.0  110.25  7.0   3  0.40   1   Avg Efficiency\n",
       "5    0.90  563.5  318.5  122.50  7.0   5  0.10   2   Avg Efficiency\n",
       "6    0.98  514.5  294.0  110.25  7.0   4  0.25   2   Avg Efficiency\n",
       "7    0.82  612.5  318.5  147.00  7.0   2  0.40   2   Avg Efficiency\n",
       "8    0.86  588.0  294.0  147.00  7.0   5  0.25   3   Avg Efficiency\n",
       "9    0.82  612.5  318.5  147.00  7.0   2  0.10   4   Avg Efficiency\n",
       "10   0.71  710.5  269.5  220.50  3.5   5  0.00   0  High Efficiency\n",
       "11   0.79  637.0  343.0  147.00  7.0   4  0.40   1   Avg Efficiency\n",
       "12   0.66  759.5  318.5  220.50  3.5   4  0.10   5  High Efficiency\n",
       "13   0.79  637.0  343.0  147.00  7.0   3  0.40   2   Avg Efficiency\n",
       "14   0.79  637.0  343.0  147.00  7.0   3  0.40   5   Low Efficiency\n",
       "15   0.86  588.0  294.0  147.00  7.0   4  0.10   4   Avg Efficiency\n",
       "16   0.71  710.5  269.5  220.50  3.5   5  0.10   3  High Efficiency\n",
       "17   0.90  563.5  318.5  122.50  7.0   5  0.10   1   Avg Efficiency\n",
       "18   0.62  808.5  367.5  220.50  3.5   5  0.25   4  High Efficiency\n",
       "19   0.71  710.5  269.5  220.50  3.5   3  0.25   2  High Efficiency\n",
       "20   0.69  735.0  294.0  220.50  3.5   3  0.25   3  High Efficiency\n",
       "21   0.98  514.5  294.0  110.25  7.0   3  0.40   2   Avg Efficiency\n",
       "22   0.71  710.5  269.5  220.50  3.5   2  0.10   3  High Efficiency\n",
       "23   0.79  637.0  343.0  147.00  7.0   2  0.25   2   Avg Efficiency\n",
       "24   0.74  686.0  245.0  220.50  3.5   5  0.00   0  High Efficiency\n",
       "25   0.71  710.5  269.5  220.50  3.5   3  0.40   2  High Efficiency\n",
       "26   0.62  808.5  367.5  220.50  3.5   5  0.10   4  High Efficiency\n",
       "27   0.74  686.0  245.0  220.50  3.5   2  0.40   5  High Efficiency\n",
       "28   0.71  710.5  269.5  220.50  3.5   5  0.10   1  High Efficiency\n",
       "29   0.79  637.0  343.0  147.00  7.0   2  0.25   5   Low Efficiency\n",
       "..    ...    ...    ...     ...  ...  ..   ...  ..              ...\n",
       "162  0.98  514.5  294.0  110.25  7.0   3  0.10   2   Avg Efficiency\n",
       "163  0.98  514.5  294.0  110.25  7.0   4  0.40   1   Avg Efficiency\n",
       "164  0.66  759.5  318.5  220.50  3.5   5  0.25   1  High Efficiency\n",
       "165  0.64  784.0  343.0  220.50  3.5   5  0.40   2  High Efficiency\n",
       "166  0.66  759.5  318.5  220.50  3.5   4  0.25   5  High Efficiency\n",
       "167  0.86  588.0  294.0  147.00  7.0   2  0.40   3   Avg Efficiency\n",
       "168  0.62  808.5  367.5  220.50  3.5   2  0.25   5  High Efficiency\n",
       "169  0.86  588.0  294.0  147.00  7.0   2  0.40   1   Avg Efficiency\n",
       "170  0.76  661.5  416.5  122.50  7.0   3  0.40   2   Low Efficiency\n",
       "171  0.71  710.5  269.5  220.50  3.5   4  0.25   4  High Efficiency\n",
       "172  0.79  637.0  343.0  147.00  7.0   3  0.00   0   Avg Efficiency\n",
       "173  0.79  637.0  343.0  147.00  7.0   5  0.40   5   Low Efficiency\n",
       "174  0.76  661.5  416.5  122.50  7.0   5  0.10   5   Low Efficiency\n",
       "175  0.98  514.5  294.0  110.25  7.0   3  0.10   5   Avg Efficiency\n",
       "176  0.86  588.0  294.0  147.00  7.0   2  0.25   2   Avg Efficiency\n",
       "177  0.82  612.5  318.5  147.00  7.0   4  0.25   1   Avg Efficiency\n",
       "178  0.69  735.0  294.0  220.50  3.5   2  0.40   4  High Efficiency\n",
       "179  0.98  514.5  294.0  110.25  7.0   2  0.10   5   Avg Efficiency\n",
       "180  0.74  686.0  245.0  220.50  3.5   4  0.10   3  High Efficiency\n",
       "181  0.79  637.0  343.0  147.00  7.0   5  0.40   4   Low Efficiency\n",
       "182  0.86  588.0  294.0  147.00  7.0   4  0.25   5   Avg Efficiency\n",
       "183  0.62  808.5  367.5  220.50  3.5   3  0.00   0  High Efficiency\n",
       "184  0.71  710.5  269.5  220.50  3.5   4  0.40   5  High Efficiency\n",
       "185  0.82  612.5  318.5  147.00  7.0   4  0.10   1   Avg Efficiency\n",
       "186  0.71  710.5  269.5  220.50  3.5   4  0.10   1  High Efficiency\n",
       "187  0.71  710.5  269.5  220.50  3.5   4  0.25   2  High Efficiency\n",
       "188  0.82  612.5  318.5  147.00  7.0   3  0.25   1   Avg Efficiency\n",
       "189  0.62  808.5  367.5  220.50  3.5   4  0.25   2  High Efficiency\n",
       "190  0.62  808.5  367.5  220.50  3.5   2  0.10   2  High Efficiency\n",
       "191  0.71  710.5  269.5  220.50  3.5   5  0.25   4  High Efficiency\n",
       "\n",
       "[192 rows x 9 columns]"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(y_predict)\n",
    "df.columns = ['New_y']\n",
    "NewX_test = X_test\n",
    "New_X_test = NewX_test.reset_index(drop=True)\n",
    "df['New_y'] = df['New_y'].map({0.0:'High Efficiency',1.0:'High Efficiency', 2.0:'Avg Efficiency', 3.0:'Low Efficiency', 4.0:'Low Efficiency'})\n",
    "new_data = pd.concat([New_X_test, df], axis=1)\n",
    "new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Frequency')"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a17bd3de10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(df)\n",
    "plt.title(\"Overall load\")\n",
    "plt.xlabel(\"Efficiency\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Conclusion\n",
    "\n",
    "After running neural network, I found that the model got a little lower R2 score compare to the Decision Tree Classification model. However, the difference between the training data set and the test data set has become smaller. Therefore, I will use the neural network model for prediction.\n",
    "\n",
    "In the model, I used the relu in order to save time and got a better R2 score. I also used 6 hidden layer in order to get the highest R2 score. Moreover, I applied the grid search on the model to find the best parameter 'batch_size' which is 5 and 50 for epochs.\n",
    "\n",
    "The following plot is the result to see the distribution of different level of efficient in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
